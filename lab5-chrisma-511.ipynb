{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Analyse application of BERT based models\nimplement BERT variants in  -\n1. Sequence classification\n2. token classification\n3. question answering\nHow is BERT'S architecture is adapted for each of these tasks\nModel selection - DistilBERT\nfor each task\n• Architecture overview\n• Pre-training objectives (MLM, NSP)\n• Dataset used for fine-tuning\n• Practical applications (e.g., sentiment analysis, NER, QA systems)","metadata":{}},{"cell_type":"markdown","source":"implementation using hugging face transfromer or Pytorch based","metadata":{}},{"cell_type":"code","source":"!pip install transformers datasets evaluate -q\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:25:58.632131Z","iopub.execute_input":"2025-07-28T23:25:58.632934Z","iopub.status.idle":"2025-07-28T23:26:01.906898Z","shell.execute_reply.started":"2025-07-28T23:25:58.632900Z","shell.execute_reply":"2025-07-28T23:26:01.905740Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"pip install seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:27:22.715352Z","iopub.execute_input":"2025-07-28T23:27:22.715665Z","iopub.status.idle":"2025-07-28T23:27:28.235193Z","shell.execute_reply.started":"2025-07-28T23:27:22.715632Z","shell.execute_reply":"2025-07-28T23:27:28.234188Z"}},"outputs":[{"name":"stdout","text":"Collecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->seqeval) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=46447edc794e0e150e114b1d7f9bacedec2baba02288f9344828228339166a6d\n  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install --upgrade transformers -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:29:20.548263Z","iopub.execute_input":"2025-07-28T23:29:20.548552Z","iopub.status.idle":"2025-07-28T23:29:32.489020Z","shell.execute_reply.started":"2025-07-28T23:29:20.548533Z","shell.execute_reply":"2025-07-28T23:29:32.488174Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"code code code","metadata":{}},{"cell_type":"markdown","source":"Task - 1 - Sequence classification(categorizes sequence of text to a particular category) Sentiment analysis o Load a pre-trained BERT model for classification (e.g., bert-base- uncased)\n\no Fine-tune it on a labeled dataset (e.g., IMDb, SST-2, Indic movie reviews) o Evaluate classification metrics like accuracy, precision, recall","metadata":{}},{"cell_type":"code","source":"!pip install transformers datasets scikit-learn -q\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:35:55.066213Z","iopub.execute_input":"2025-07-28T23:35:55.066513Z","iopub.status.idle":"2025-07-28T23:35:58.355123Z","shell.execute_reply.started":"2025-07-28T23:35:55.066488Z","shell.execute_reply":"2025-07-28T23:35:58.354187Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom torch.nn import CrossEntropyLoss\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom torch.optim import AdamW\nfrom datasets import load_dataset\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# 1. Load IMDb dataset\ndataset = load_dataset(\"imdb\")\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\n# 2. Tokenize function\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n\n# Convert to PyTorch format\ntokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n\n# Small subset for faster demo\ntrain_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(2000))\ntest_dataset = tokenized_dataset[\"test\"].shuffle(seed=42).select(range(1000))\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=8)\n\n# 3. Load BERT model\nmodel = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# 4. Optimizer and loss\noptimizer = AdamW(model.parameters(), lr=2e-5)\nloss_fn = CrossEntropyLoss()\n\n# 5. Training loop (1 epoch for demo)\nmodel.train()\nfor batch in train_loader:\n    optimizer.zero_grad()\n    input_ids = batch[\"input_ids\"].to(device)\n    attention_mask = batch[\"attention_mask\"].to(device)\n    labels = batch[\"label\"].to(device)\n    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n    loss = outputs.loss\n    loss.backward()\n    optimizer.step()\n\n# 6. Evaluation\nmodel.eval()\nall_preds = []\nall_labels = []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"label\"].to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        preds = torch.argmax(outputs.logits, dim=1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# 7. Metrics using sklearn\nacc = accuracy_score(all_labels, all_preds)\nprec = precision_score(all_labels, all_preds)\nrec = recall_score(all_labels, all_preds)\nf1 = f1_score(all_labels, all_preds)\n\nprint(f\"Accuracy: {acc:.4f}\")\nprint(f\"Precision: {prec:.4f}\")\nprint(f\"Recall: {rec:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:36:55.327060Z","iopub.execute_input":"2025-07-28T23:36:55.327365Z","iopub.status.idle":"2025-07-28T23:39:39.044526Z","shell.execute_reply.started":"2025-07-28T23:36:55.327345Z","shell.execute_reply":"2025-07-28T23:39:39.043865Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7db47ec83ad470683fcc41ace98edbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36202de1d8de426a8d56b7cb6e9e767a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be3102f8154e4330b952639841022f2c"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8760\nPrecision: 0.8957\nRecall: 0.8443\nF1 Score: 0.8692\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import AdamW\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\nfrom datasets import load_dataset\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# 1. Load dataset (CoNLL-2003)\ndataset = load_dataset(\"conll2003\")\n\n# Labels\nlabel_names = dataset[\"train\"].features[\"ner_tags\"].feature.names\nnum_labels = len(label_names)\n\n# 2. Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"],\n        truncation=True,\n        is_split_into_words=True,\n        max_length=128,\n        padding=\"max_length\"\n    )\n    labels = []\n    for i, label in enumerate(examples[\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        label_ids = []\n        for word_id in word_ids:\n            if word_id is None:\n                label_ids.append(-100)  # ignored in loss\n            else:\n                label_ids.append(label[word_id])\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs\n\ntokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)\ntokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n\n# Small subset for quick training\ntrain_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(2000))\ntest_dataset = tokenized_dataset[\"validation\"].shuffle(seed=42).select(range(500))\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=8)\n\n# 3. Model\nmodel = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=num_labels)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# 4. Optimizer & Loss\noptimizer = AdamW(model.parameters(), lr=5e-5)\nloss_fn = CrossEntropyLoss()\n\n# 5. Training loop (1 epoch for demo)\nmodel.train()\nfor batch in train_loader:\n    optimizer.zero_grad()\n    input_ids = batch[\"input_ids\"].to(device)\n    attention_mask = batch[\"attention_mask\"].to(device)\n    labels = batch[\"labels\"].to(device)\n    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n    loss = outputs.loss\n    loss.backward()\n    optimizer.step()\n\n# 6. Evaluation\nmodel.eval()\ntrue_labels, pred_labels = [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=2)\n\n        for label_seq, pred_seq, mask in zip(labels, predictions, attention_mask):\n            true_seq = []\n            pred_seq_out = []\n            for l, p, m in zip(label_seq, pred_seq, mask):\n                if m == 1 and l != -100:  # only valid tokens\n                    true_seq.append(l.item())\n                    pred_seq_out.append(p.item())\n            true_labels.extend(true_seq)\n            pred_labels.extend(pred_seq_out)\n\n# Convert indices to labels\ntrue_labels_names = [label_names[i] for i in true_labels]\npred_labels_names = [label_names[i] for i in pred_labels]\n\n# Compute metrics\nprecision = precision_score(true_labels_names, pred_labels_names, average=\"micro\")\nrecall = recall_score(true_labels_names, pred_labels_names, average=\"micro\")\nf1 = f1_score(true_labels_names, pred_labels_names, average=\"micro\")\n\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:42:25.681286Z","iopub.execute_input":"2025-07-28T23:42:25.681839Z","iopub.status.idle":"2025-07-28T23:42:50.397528Z","shell.execute_reply.started":"2025-07-28T23:42:25.681803Z","shell.execute_reply":"2025-07-28T23:42:50.396835Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc3a9a28f81f4cf485aaeb4b7203f607"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30f02e20434d4c32816924a58a41e18d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e09f313c270a4139907ec44d308cf35c"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Precision: 0.9661\nRecall: 0.9661\nF1 Score: 0.9661\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"Task - 2 - Token classification\nuse case named entity recognition\n\no Token Classification: Entity-level precision, recall","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\nfrom datasets import load_dataset\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# 1. Load dataset (SQuAD small subset for demo)\ndataset = load_dataset(\"squad\")\ntest_dataset = dataset[\"validation\"].select(range(200))  # subset for speed\n\n# 2. Load model & tokenizer\nmodel_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()\n\n# 3. Prediction loop\ndef get_answer(question, context):\n    inputs = tokenizer(question, context, return_tensors=\"pt\", truncation=True).to(device)\n    with torch.no_grad():\n        outputs = model(**inputs)\n    start_idx = torch.argmax(outputs.start_logits)\n    end_idx = torch.argmax(outputs.end_logits) + 1\n    answer_ids = inputs[\"input_ids\"][0][start_idx:end_idx]\n    return tokenizer.decode(answer_ids, skip_special_tokens=True)\n\n# 4. Evaluate on subset\nexact_match = 0\nf1_total = 0\n\ndef compute_f1(prediction, ground_truth):\n    pred_tokens = prediction.lower().split()\n    truth_tokens = ground_truth.lower().split()\n    common = set(pred_tokens) & set(truth_tokens)\n    if len(common) == 0:\n        return 0\n    precision = len(common) / len(pred_tokens)\n    recall = len(common) / len(truth_tokens)\n    return (2 * precision * recall) / (precision + recall)\n\nfor example in test_dataset:\n    pred_answer = get_answer(example[\"question\"], example[\"context\"])\n    true_answer = example[\"answers\"][\"text\"][0]\n\n    # Exact match\n    if pred_answer.lower().strip() == true_answer.lower().strip():\n        exact_match += 1\n\n    # F1\n    f1_total += compute_f1(pred_answer, true_answer)\n\nnum_samples = len(test_dataset)\nem_score = (exact_match / num_samples) * 100\nf1_score_avg = (f1_total / num_samples) * 100\n\nprint(f\"Exact Match (EM): {em_score:.2f}\")\nprint(f\"F1 Score: {f1_score_avg:.2f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:44:16.624190Z","iopub.execute_input":"2025-07-28T23:44:16.624933Z","iopub.status.idle":"2025-07-28T23:44:26.308240Z","shell.execute_reply.started":"2025-07-28T23:44:16.624910Z","shell.execute_reply":"2025-07-28T23:44:26.307621Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d6ab7b1ce14403fadd256aa0c837312"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"265b8b54488b481989918e028d31b5d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/1.82M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df929dff4ce341aa8edd88ef011facc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03b2718b0ed7480380e62ac3d09b7e6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f0cc00cf9474248b2f6e1e7cd6e25f8"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"Exact Match (EM): 69.00\nF1 Score: 77.30\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"Task - 3 - question answering\nQA: Exact Match (EM), F1\n• Discuss strengths and limitations observed during experiments","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n\nsequence_cls_metrics = {\"Accuracy\": 0.8760, \"Precision\": 0.8957, \"Recall\": 0.8443, \"F1\": 0.8692}\ntoken_cls_metrics = {\"Precision\": 0.9661, \"Recall\": 0.9661, \"F1\": 0.9661}\nqa_metrics = {\"Exact Match\": 0.69, \"F1\": 0.7730}\n\n# Combine metrics (fill missing with np.nan)\nlabels = [\"Sequence Classification\", \"Token Classification\", \"Question Answering\"]\naccuracy = [sequence_cls_metrics[\"Accuracy\"], np.nan, np.nan]\nprecision = [sequence_cls_metrics[\"Precision\"], token_cls_metrics[\"Precision\"], np.nan]\nrecall = [sequence_cls_metrics[\"Recall\"], token_cls_metrics[\"Recall\"], np.nan]\nf1 = [sequence_cls_metrics[\"F1\"], token_cls_metrics[\"F1\"], qa_metrics[\"F1\"]]\nexact_match = [np.nan, np.nan, qa_metrics[\"Exact Match\"]]\n\nx = np.arange(len(labels))\nwidth = 0.15\n\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Bars\nax.bar(x - 2*width, [v if not np.isnan(v) else 0 for v in accuracy], width, label=\"Accuracy\")\nax.bar(x - width, [v if not np.isnan(v) else 0 for v in precision], width, label=\"Precision\")\nax.bar(x, [v if not np.isnan(v) else 0 for v in recall], width, label=\"Recall\")\nax.bar(x + width, [v if not np.isnan(v) else 0 for v in f1], width, label=\"F1 Score\")\nax.bar(x + 2*width, [v if not np.isnan(v) else 0 for v in exact_match], width, label=\"Exact Match\")\n\n# Axis settings\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.set_ylim(0, 1.1)\nax.set_ylabel(\"Score\")\nax.set_title(\"Comparison of BERT-based Models on NLP Tasks\")\nax.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:46:08.606898Z","iopub.execute_input":"2025-07-28T23:46:08.607587Z","iopub.status.idle":"2025-07-28T23:46:08.841563Z","shell.execute_reply.started":"2025-07-28T23:46:08.607568Z","shell.execute_reply":"2025-07-28T23:46:08.840840Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"Token Classification > Sequence Classification > Question Answering in terms of raw metrics.\n\nBERT-based models show strong performance on structured tasks (token-level & sequence-level) where class boundaries are clearer.\n\nQuestion Answering is more challenging, requiring span prediction and deeper contextual reasoning, hence slightly lower scores.\n\nFine-tuning BERT for each task demonstrates that BERT is versatile, performing well across very different NLP tasks.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Data for the table\ndata = {\n    \"Task\": [\n        \"Sequence Classification (Sentiment Analysis)\",\n        \"Token Classification (NER)\",\n        \"Question Answering (Extractive QA)\"\n    ],\n    \"Dataset Used\": [\n        \"IMDb\",\n        \"CoNLL-2003\",\n        \"SQuAD (fine-tuned)\"\n    ],\n    \"Model Used\": [\n        \"bert-base-uncased\",\n        \"distilbert-base-uncased\",\n        \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n    ],\n    \"Evaluation Metrics\": [\n        \"Accuracy: 0.8760\\nPrecision: 0.8957\\nRecall: 0.8443\\nF1: 0.8692\",\n        \"Precision: 0.9661\\nRecall: 0.9661\\nF1: 0.9661\",\n        \"Exact Match: 0.69\\nF1: 0.7730\"\n    ],\n    \"Inference\": [\n        \"Strong generalization and balanced performance, slightly higher precision than recall, indicating reliable positive predictions.\",\n        \"Near-perfect performance with DistilBERT showing efficiency and speed without sacrificing accuracy.\",\n        \"Good semantic understanding with contextual answers, though exact span prediction remains challenging (lower EM).\"\n    ]\n}\n\n# Create DataFrame\ndf = pd.DataFrame(data)\n\n# Apply styling for better readability\nstyled_table = df.style.set_properties(**{\n    'white-space': 'pre-wrap',  # wrap text\n    'word-wrap': 'break-word',\n    'border': '1px solid black',\n    'text-align': 'left'\n}).set_table_styles([\n    {'selector': 'th', 'props': [('font-size', '12pt'), ('text-align', 'center'), ('background-color', '#f2f2f2')]},\n    {'selector': 'td', 'props': [('font-size', '11pt'), ('padding', '8px')]}\n])\n\n# Display table\nstyled_table\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T05:02:33.302975Z","iopub.execute_input":"2025-07-31T05:02:33.303547Z","iopub.status.idle":"2025-07-31T05:02:33.435267Z","shell.execute_reply.started":"2025-07-31T05:02:33.303524Z","shell.execute_reply":"2025-07-31T05:02:33.434676Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7a55763e56d0>","text/html":"<style type=\"text/css\">\n#T_7b4e7 th {\n  font-size: 12pt;\n  text-align: center;\n  background-color: #f2f2f2;\n}\n#T_7b4e7 td {\n  font-size: 11pt;\n  padding: 8px;\n}\n#T_7b4e7_row0_col0, #T_7b4e7_row0_col1, #T_7b4e7_row0_col2, #T_7b4e7_row0_col3, #T_7b4e7_row0_col4, #T_7b4e7_row1_col0, #T_7b4e7_row1_col1, #T_7b4e7_row1_col2, #T_7b4e7_row1_col3, #T_7b4e7_row1_col4, #T_7b4e7_row2_col0, #T_7b4e7_row2_col1, #T_7b4e7_row2_col2, #T_7b4e7_row2_col3, #T_7b4e7_row2_col4 {\n  white-space: pre-wrap;\n  word-wrap: break-word;\n  border: 1px solid black;\n  text-align: left;\n}\n</style>\n<table id=\"T_7b4e7\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_7b4e7_level0_col0\" class=\"col_heading level0 col0\" >Task</th>\n      <th id=\"T_7b4e7_level0_col1\" class=\"col_heading level0 col1\" >Dataset Used</th>\n      <th id=\"T_7b4e7_level0_col2\" class=\"col_heading level0 col2\" >Model Used</th>\n      <th id=\"T_7b4e7_level0_col3\" class=\"col_heading level0 col3\" >Evaluation Metrics</th>\n      <th id=\"T_7b4e7_level0_col4\" class=\"col_heading level0 col4\" >Inference</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_7b4e7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_7b4e7_row0_col0\" class=\"data row0 col0\" >Sequence Classification (Sentiment Analysis)</td>\n      <td id=\"T_7b4e7_row0_col1\" class=\"data row0 col1\" >IMDb</td>\n      <td id=\"T_7b4e7_row0_col2\" class=\"data row0 col2\" >bert-base-uncased</td>\n      <td id=\"T_7b4e7_row0_col3\" class=\"data row0 col3\" >Accuracy: 0.8760\nPrecision: 0.8957\nRecall: 0.8443\nF1: 0.8692</td>\n      <td id=\"T_7b4e7_row0_col4\" class=\"data row0 col4\" >Strong generalization and balanced performance, slightly higher precision than recall, indicating reliable positive predictions.</td>\n    </tr>\n    <tr>\n      <th id=\"T_7b4e7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_7b4e7_row1_col0\" class=\"data row1 col0\" >Token Classification (NER)</td>\n      <td id=\"T_7b4e7_row1_col1\" class=\"data row1 col1\" >CoNLL-2003</td>\n      <td id=\"T_7b4e7_row1_col2\" class=\"data row1 col2\" >distilbert-base-uncased</td>\n      <td id=\"T_7b4e7_row1_col3\" class=\"data row1 col3\" >Precision: 0.9661\nRecall: 0.9661\nF1: 0.9661</td>\n      <td id=\"T_7b4e7_row1_col4\" class=\"data row1 col4\" >Near-perfect performance with DistilBERT showing efficiency and speed without sacrificing accuracy.</td>\n    </tr>\n    <tr>\n      <th id=\"T_7b4e7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_7b4e7_row2_col0\" class=\"data row2 col0\" >Question Answering (Extractive QA)</td>\n      <td id=\"T_7b4e7_row2_col1\" class=\"data row2 col1\" >SQuAD (fine-tuned)</td>\n      <td id=\"T_7b4e7_row2_col2\" class=\"data row2 col2\" >bert-large-uncased-whole-word-masking-finetuned-squad</td>\n      <td id=\"T_7b4e7_row2_col3\" class=\"data row2 col3\" >Exact Match: 0.69\nF1: 0.7730</td>\n      <td id=\"T_7b4e7_row2_col4\" class=\"data row2 col4\" >Good semantic understanding with contextual answers, though exact span prediction remains challenging (lower EM).</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# For Sequence Classification\nmodel.save_pretrained(\"sequence_model\")        # sequence model object\ntokenizer.save_pretrained(\"sequence_model\")\n\n# For Token Classification (NER)\nmodel.save_pretrained(\"token_model\")           # after training token classification task\ntokenizer.save_pretrained(\"token_model\")\n\n# For Question Answering\nmodel.save_pretrained(\"qa_model\")              # after QA task\ntokenizer.save_pretrained(\"qa_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:48:55.268625Z","iopub.execute_input":"2025-07-28T23:48:55.268951Z","iopub.status.idle":"2025-07-28T23:49:01.508053Z","shell.execute_reply.started":"2025-07-28T23:48:55.268928Z","shell.execute_reply":"2025-07-28T23:49:01.507212Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"('qa_model/tokenizer_config.json',\n 'qa_model/special_tokens_map.json',\n 'qa_model/vocab.txt',\n 'qa_model/added_tokens.json',\n 'qa_model/tokenizer.json')"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"import shutil\nimport os\n\n# Paths where models were saved after training\nsequence_model_dir = \"/kaggle/working/sequence_model\"\ntoken_model_dir = \"/kaggle/working/token_model\"\nqa_model_dir = \"/kaggle/working/qa_model\"\n\n# Ensure directories exist\nos.makedirs(sequence_model_dir, exist_ok=True)\nos.makedirs(token_model_dir, exist_ok=True)\nos.makedirs(qa_model_dir, exist_ok=True)\n\n# Zip models using shutil.make_archive\nshutil.make_archive(\"/kaggle/working/sequence_model\", 'zip', sequence_model_dir)\nshutil.make_archive(\"/kaggle/working/token_model\", 'zip', token_model_dir)\nshutil.make_archive(\"/kaggle/working/qa_model\", 'zip', qa_model_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T23:51:01.432354Z","iopub.execute_input":"2025-07-28T23:51:01.433223Z","iopub.status.idle":"2025-07-28T23:54:17.414427Z","shell.execute_reply.started":"2025-07-28T23:51:01.433190Z","shell.execute_reply":"2025-07-28T23:54:17.413688Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/qa_model.zip'"},"metadata":{}}],"execution_count":26}]}